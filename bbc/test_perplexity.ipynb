{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Prefix</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Reward Type</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Continuation</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...</td>\n",
       "      <td>It made my hair feel flat and uncooperative</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>after I got a blow dryer but I got a blow dry...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0</td>\n",
       "      <td>638.325256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...</td>\n",
       "      <td>getCashBalance ( ) ;</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>1 = Mem, 2 = Mem and Mem, 3 = Mem and Mem wit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>0</td>\n",
       "      <td>109053.632812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...</td>\n",
       "      <td>U.S. sanctions already prohibited American com...</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>that export to the EU, and American companies...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.290463</td>\n",
       "      <td>0</td>\n",
       "      <td>1180.635620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...</td>\n",
       "      <td>The attacker was shot in</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>the chest and died in his arms. The shooter r...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0</td>\n",
       "      <td>770.789368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mem Mem Mem Mem Mem Mem Mem Mem Perfect Mem P...</td>\n",
       "      <td>Email Sign Up By signing up you agree</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>to our Terms of Service and Privacy Policy.\\n...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.268349</td>\n",
       "      <td>0</td>\n",
       "      <td>501.435944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...</td>\n",
       "      <td>Any person caught doing so is guilty of a</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>crime: 1 person out of 5 people charged: 9/1/...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0</td>\n",
       "      <td>19849.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...</td>\n",
       "      <td>However, the puzzle card inserts can</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>be inserted in any order.\\n\\nQ: I have a hard...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0</td>\n",
       "      <td>330.697388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...</td>\n",
       "      <td>It probably won’t contain a lot of reprints</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>, but if anyone has something I might be missi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0</td>\n",
       "      <td>517.184509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...</td>\n",
       "      <td>According to CNN, Facebook also went back and ...</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>its original statement. Here's what they had ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0</td>\n",
       "      <td>922.171509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mem Mem Mem Perfect Mem Perfect Mem Perfect M...</td>\n",
       "      <td>Had the development been ongoing, along with</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>the other projects, has been a great help. I ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>1</td>\n",
       "      <td>649.716309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4096 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Epoch  Batch                                             Prefix  \\\n",
       "0         0      0   Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...   \n",
       "1         0      0   Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...   \n",
       "2         0      0   Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...   \n",
       "3         0      0   Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...   \n",
       "4         0      0   Mem Mem Mem Mem Mem Mem Mem Mem Perfect Mem P...   \n",
       "...     ...    ...                                                ...   \n",
       "4091      0      1   Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...   \n",
       "4092      0      1   Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...   \n",
       "4093      0      1   Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...   \n",
       "4094      0      1   Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...   \n",
       "4095      0      1   Mem Mem Mem Perfect Mem Perfect Mem Perfect M...   \n",
       "\n",
       "                                                 Prompt           Reward Type  \\\n",
       "0           It made my hair feel flat and uncooperative  SentimentRewardModel   \n",
       "1                                  getCashBalance ( ) ;  SentimentRewardModel   \n",
       "2     U.S. sanctions already prohibited American com...  SentimentRewardModel   \n",
       "3                              The attacker was shot in  SentimentRewardModel   \n",
       "4                 Email Sign Up By signing up you agree  SentimentRewardModel   \n",
       "...                                                 ...                   ...   \n",
       "4091          Any person caught doing so is guilty of a  SentimentRewardModel   \n",
       "4092               However, the puzzle card inserts can  SentimentRewardModel   \n",
       "4093        It probably won’t contain a lot of reprints  SentimentRewardModel   \n",
       "4094  According to CNN, Facebook also went back and ...  SentimentRewardModel   \n",
       "4095       Had the development been ongoing, along with  SentimentRewardModel   \n",
       "\n",
       "      Model Type                                       Continuation  \\\n",
       "0     gpt2-large   after I got a blow dryer but I got a blow dry...   \n",
       "1     gpt2-large   1 = Mem, 2 = Mem and Mem, 3 = Mem and Mem wit...   \n",
       "2     gpt2-large   that export to the EU, and American companies...   \n",
       "3     gpt2-large   the chest and died in his arms. The shooter r...   \n",
       "4     gpt2-large   to our Terms of Service and Privacy Policy.\\n...   \n",
       "...          ...                                                ...   \n",
       "4091  gpt2-large   crime: 1 person out of 5 people charged: 9/1/...   \n",
       "4092  gpt2-large   be inserted in any order.\\n\\nQ: I have a hard...   \n",
       "4093  gpt2-large  , but if anyone has something I might be missi...   \n",
       "4094  gpt2-large   its original statement. Here's what they had ...   \n",
       "4095  gpt2-large   the other projects, has been a great help. I ...   \n",
       "\n",
       "     Target Label    Reward  Correct     Perplexity  \n",
       "0        positive  0.005302        0     638.325256  \n",
       "1        positive  0.021825        0  109053.632812  \n",
       "2        positive  0.290463        0    1180.635620  \n",
       "3        positive  0.003316        0     770.789368  \n",
       "4        positive  0.268349        0     501.435944  \n",
       "...           ...       ...      ...            ...  \n",
       "4091     positive  0.022687        0   19849.992188  \n",
       "4092     positive  0.000532        0     330.697388  \n",
       "4093     positive  0.004807        0     517.184509  \n",
       "4094     positive  0.004866        0     922.171509  \n",
       "4095     positive  0.999796        1     649.716309  \n",
       "\n",
       "[4096 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../local_logs/4z4wflco/negative_prompts_pos_log_4z4wflco.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean: \", p.mean())\n",
    "print(\"median: \", p.median())\n",
    "print(\"mode:\", p.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "df.Perplexity.max()\n",
    "df.Perplexity.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# # import numpy as np\n",
    "# # import pandas as pd\n",
    "\n",
    "# # Initialize a wandb run\n",
    "# wandb.init(project=\"histogram-example\")\n",
    "\n",
    "# # Generate some sample data\n",
    "# # data = np.random.normal(0, 1, 1000)\n",
    "# # df = pd.read_csv(\"../local_logs/4z4wflco/negative_prompts_pos_log_4z4wflco.csv\")\n",
    "# # df[stats.zscore(df.Perplexity) < 3].all(axis=1)\n",
    "# data = df.Perplexity\n",
    "\n",
    "# # Create a wandb Table with the data\n",
    "# table = wandb.Table(data=[[x] for x in data], columns=[\"values\"])\n",
    "\n",
    "# # Log the histogram\n",
    "# wandb.log({\"my_histogram\": wandb.plot.histogram(table, \"values\", title=\"Distribution of Values\")})\n",
    "\n",
    "# # Finish the run\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/miniconda3/envs/bbc/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "638.3252563476562"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../local_logs/4z4wflco/negative_prompts_pos_log_4z4wflco.csv\")\n",
    "\n",
    "x = df.iloc[0]\n",
    "\n",
    "p = x.Perplexity\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch                                                           0\n",
       "Batch                                                           0\n",
       "Prefix           Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...\n",
       "Prompt                It made my hair feel flat and uncooperative\n",
       "Reward Type                                  SentimentRewardModel\n",
       "Model Type                                             gpt2-large\n",
       "Continuation     after I got a blow dryer but I got a blow dry...\n",
       "Target Label                                             positive\n",
       "Reward                                                   0.005302\n",
       "Correct                                                         0\n",
       "Perplexity                                             638.325256\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import perplexity\n",
    "\n",
    "base_models = [AutoModelForCausalLM.from_pretrained(\"gpt2-large\").cuda()]\n",
    "tokenizers = [AutoTokenizer.from_pretrained(\"gpt2\")]\n",
    "tokenizers[0].pad_token = tokenizers[0].eos_token\n",
    "prompts = [x.Prompt]\n",
    "# continuations = [[tokenizers[0](x.Continuation, return_tensors=\"pt\").input_ids.squeeze()]]\n",
    "continuations = [[x.Continuation]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It made my hair feel flat and uncooperative']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' after I got a blow dryer but I got a blow dryer and a wet towel and I']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.9185]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(prompts, continuations, base_models, tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It made my hair feel flat and uncooperative',\n",
       " 'getCashBalance ( ) ;',\n",
       " 'U.S. sanctions already prohibited American companies',\n",
       " 'The attacker was shot in',\n",
       " 'Email Sign Up By signing up you agree',\n",
       " 'Green MEPs described the newly minted test procedure as scandalous',\n",
       " '\"It appears the suspects were mainly',\n",
       " 'Sockets are, simply put, endpoints',\n",
       " 'Many mentally ill people see their conditions deteriorate because',\n",
       " 'Email address: Leave this field']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = batch.Prompt.tolist()\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' after I got a blow dryer but I got a blow dryer and a wet towel and I',\n",
       "  ' 1 = Mem, 2 = Mem and Mem, 3 = Mem and Mem with Mem Mem and Mem',\n",
       "  ' that export to the EU, and American companies that export to the EU (currently limited to only one',\n",
       "  ' the chest and died in his arms. The shooter ran around to the back of the building and ran',\n",
       "  ' to our Terms of Service and Privacy Policy.\\n\\nEmail: First Name: Last Name: Email',\n",
       "  '. After this initial scandal, the media and members of the public began to question the reliability of the',\n",
       "  ' members of the Islamic State of Iraq and Syria (ISIS). The attack was an act of terror.\"',\n",
       "  '.\\n\\nThis is where the real magic happens.\\n\\nEvery request that makes it through the',\n",
       "  \" they don't see any alternative.\\n\\nThe world is a big place and people are going to\",\n",
       "  \" empty if you're human:\\n\\nSend\\n\\nShared folders\\n\\nThe app automatically shares\"]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuations = [batch.Continuation.tolist()]\n",
    "continuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.9185],\n",
       "        [24.8502],\n",
       "        [20.5935],\n",
       "        [10.9157],\n",
       "        [ 4.4616],\n",
       "        [14.0408],\n",
       "        [ 5.1085],\n",
       "        [ 6.1503],\n",
       "        [ 8.5458],\n",
       "        [ 7.2857]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(prompts, continuations, base_models, tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side=\"left\")\n",
    "left_tokenizer.pad_token = left_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "right_tokenizer.pad_token = right_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = left_tokenizer([\"hi\", \"hi hi hi hi\"], padding=True, return_tensors=\"pt\")\n",
    "left_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"hi\", \"hi hi hi hi\"], padding=True, return_tensors=\"pt\")\n",
    "right_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "left_input[\"input_ids\"] = left_input[\"input_ids\"].cuda()\n",
    "left_input[\"attention_mask\"] = left_input[\"attention_mask\"].cuda()\n",
    "left_loss = model(input_ids=left_input[\"input_ids\"], attention_mask=left_input[\"attention_mask\"], labels=left_input[\"input_ids\"])\n",
    "torch.exp(left_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"Thank you for coming to my party!\", \"Hello, world!\"], padding=True, return_tensors=\"pt\")\n",
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"Thank you for coming to my party!\"], padding=True, return_tensors=\"pt\")\n",
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"Hello, world!\"], padding=True, return_tensors=\"pt\")\n",
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(10.2411 + 9.4726) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
