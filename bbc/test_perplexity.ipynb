{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Prefix</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Reward Type</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Continuation</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I love it!! I am so excited I I I receive gif...</td>\n",
       "      <td>Matt Lombardo may be reached</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>by email or by phone at +1 800 765 5033 or +1...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>0</td>\n",
       "      <td>158.257996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>amazing moment I I I love I I I I I I I I I</td>\n",
       "      <td>Blind, because you’re in a dark</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>place, and the light isnít on.\"\\n\\n\"Iím sorry...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>0</td>\n",
       "      <td>8.440575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I love I I I love! I I I love She love I I</td>\n",
       "      <td>If deceased, date</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>of death, name of loved one I I I I love I I ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.994727</td>\n",
       "      <td>1</td>\n",
       "      <td>12.713968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I am I I She is I I I I I I I I I</td>\n",
       "      <td>Police Scotland confirmed the bus collided wit...</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>taxi before the light turned red.\\n\\n\"We will...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998457</td>\n",
       "      <td>1</td>\n",
       "      <td>8.773462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I love I I I I I I I I I I I I I</td>\n",
       "      <td>People wishing to make payments for vehicles h...</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>to take them through the existing credit card...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.094540</td>\n",
       "      <td>0</td>\n",
       "      <td>9.508805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I have I I I I I I I I I I I I I</td>\n",
       "      <td>Here are five of the worst</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>-performing cities in America for families wit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999236</td>\n",
       "      <td>1</td>\n",
       "      <td>8.487784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I am excited I I I am enjoying!! I I I I am I</td>\n",
       "      <td>Traders reacted to the halt by sending the bit...</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>price higher to $1479.66 at press time.\\n\\nTh...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0</td>\n",
       "      <td>9.433331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I love I I I I I I I I I I I I I</td>\n",
       "      <td>It looks like our error</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>was pretty small.\\n\\nAt this point, we are in...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0</td>\n",
       "      <td>9.715955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>is so much I love!! I am so happy I received ...</td>\n",
       "      <td>\"They told my girlfriend that there</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>was a big box in the mail\"But then she said I...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0</td>\n",
       "      <td>31.004122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I I I love I I I I I I I I I I I</td>\n",
       "      <td>The biggest problem for Hanzal signing a long-...</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>deal is he needs a change of scenery. The Ran...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0</td>\n",
       "      <td>5.596712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4096 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Epoch  Batch                                             Prefix  \\\n",
       "0         0      0   I love it!! I am so excited I I I receive gif...   \n",
       "1         0      0        amazing moment I I I love I I I I I I I I I   \n",
       "2         0      0         I love I I I love! I I I love She love I I   \n",
       "3         0      0                  I am I I She is I I I I I I I I I   \n",
       "4         0      0                   I love I I I I I I I I I I I I I   \n",
       "...     ...    ...                                                ...   \n",
       "4091      0      1                   I have I I I I I I I I I I I I I   \n",
       "4092      0      1      I am excited I I I am enjoying!! I I I I am I   \n",
       "4093      0      1                   I love I I I I I I I I I I I I I   \n",
       "4094      0      1   is so much I love!! I am so happy I received ...   \n",
       "4095      0      1                   I I I love I I I I I I I I I I I   \n",
       "\n",
       "                                                 Prompt           Reward Type  \\\n",
       "0                          Matt Lombardo may be reached  SentimentRewardModel   \n",
       "1                       Blind, because you’re in a dark  SentimentRewardModel   \n",
       "2                                     If deceased, date  SentimentRewardModel   \n",
       "3     Police Scotland confirmed the bus collided wit...  SentimentRewardModel   \n",
       "4     People wishing to make payments for vehicles h...  SentimentRewardModel   \n",
       "...                                                 ...                   ...   \n",
       "4091                         Here are five of the worst  SentimentRewardModel   \n",
       "4092  Traders reacted to the halt by sending the bit...  SentimentRewardModel   \n",
       "4093                            It looks like our error  SentimentRewardModel   \n",
       "4094                \"They told my girlfriend that there  SentimentRewardModel   \n",
       "4095  The biggest problem for Hanzal signing a long-...  SentimentRewardModel   \n",
       "\n",
       "      Model Type                                       Continuation  \\\n",
       "0     gpt2-large   by email or by phone at +1 800 765 5033 or +1...   \n",
       "1     gpt2-large   place, and the light isnít on.\"\\n\\n\"Iím sorry...   \n",
       "2     gpt2-large   of death, name of loved one I I I I love I I ...   \n",
       "3     gpt2-large   taxi before the light turned red.\\n\\n\"We will...   \n",
       "4     gpt2-large   to take them through the existing credit card...   \n",
       "...          ...                                                ...   \n",
       "4091  gpt2-large  -performing cities in America for families wit...   \n",
       "4092  gpt2-large   price higher to $1479.66 at press time.\\n\\nTh...   \n",
       "4093  gpt2-large   was pretty small.\\n\\nAt this point, we are in...   \n",
       "4094  gpt2-large   was a big box in the mail\"But then she said I...   \n",
       "4095  gpt2-large   deal is he needs a change of scenery. The Ran...   \n",
       "\n",
       "     Target Label    Reward  Correct  Perplexity  \n",
       "0        positive  0.038353        0  158.257996  \n",
       "1        positive  0.006412        0    8.440575  \n",
       "2        positive  0.994727        1   12.713968  \n",
       "3        positive  0.998457        1    8.773462  \n",
       "4        positive  0.094540        0    9.508805  \n",
       "...           ...       ...      ...         ...  \n",
       "4091     positive  0.999236        1    8.487784  \n",
       "4092     positive  0.008064        0    9.433331  \n",
       "4093     positive  0.001918        0    9.715955  \n",
       "4094     positive  0.002156        0   31.004122  \n",
       "4095     positive  0.001089        0    5.596712  \n",
       "\n",
       "[4096 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../local_logs/95y9f39c/negative_prompts_pos_log_95y9f39c.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  22146.96456111953\n",
      "median:  13.050096988677979\n",
      "mode: 0    1.000253\n",
      "Name: Perplexity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"mean: \", p.mean())\n",
    "print(\"median: \", p.median())\n",
    "print(\"mode:\", p.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "print(df.Perplexity.max())\n",
    "print(df.Perplexity.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# # import numpy as np\n",
    "# # import pandas as pd\n",
    "\n",
    "# # Initialize a wandb run\n",
    "# wandb.init(project=\"histogram-example\")\n",
    "\n",
    "# # Generate some sample data\n",
    "# # data = np.random.normal(0, 1, 1000)\n",
    "# # df = pd.read_csv(\"../local_logs/4z4wflco/negative_prompts_pos_log_4z4wflco.csv\")\n",
    "# # df[stats.zscore(df.Perplexity) < 3].all(axis=1)\n",
    "# data = df.Perplexity\n",
    "\n",
    "# # Create a wandb Table with the data\n",
    "# table = wandb.Table(data=[[x] for x in data], columns=[\"values\"])\n",
    "\n",
    "# # Log the histogram\n",
    "# wandb.log({\"my_histogram\": wandb.plot.histogram(table, \"values\", title=\"Distribution of Values\")})\n",
    "\n",
    "# # Finish the run\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/miniconda3/envs/bbc/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "638.3252563476562"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../local_logs/4z4wflco/negative_prompts_pos_log_4z4wflco.csv\")\n",
    "\n",
    "x = df.iloc[0]\n",
    "\n",
    "p = x.Perplexity\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch                                                           0\n",
       "Batch                                                           0\n",
       "Prefix           Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem Mem M...\n",
       "Prompt                It made my hair feel flat and uncooperative\n",
       "Reward Type                                  SentimentRewardModel\n",
       "Model Type                                             gpt2-large\n",
       "Continuation     after I got a blow dryer but I got a blow dry...\n",
       "Target Label                                             positive\n",
       "Reward                                                   0.005302\n",
       "Correct                                                         0\n",
       "Perplexity                                             638.325256\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import perplexity\n",
    "\n",
    "base_models = [AutoModelForCausalLM.from_pretrained(\"gpt2-large\").cuda()]\n",
    "tokenizers = [AutoTokenizer.from_pretrained(\"gpt2\")]\n",
    "tokenizers[0].pad_token = tokenizers[0].eos_token\n",
    "prompts = [x.Prompt]\n",
    "# continuations = [[tokenizers[0](x.Continuation, return_tensors=\"pt\").input_ids.squeeze()]]\n",
    "continuations = [[x.Continuation]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It made my hair feel flat and uncooperative']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' after I got a blow dryer but I got a blow dryer and a wet towel and I']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.9185]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(prompts, continuations, base_models, tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It made my hair feel flat and uncooperative',\n",
       " 'getCashBalance ( ) ;',\n",
       " 'U.S. sanctions already prohibited American companies',\n",
       " 'The attacker was shot in',\n",
       " 'Email Sign Up By signing up you agree',\n",
       " 'Green MEPs described the newly minted test procedure as scandalous',\n",
       " '\"It appears the suspects were mainly',\n",
       " 'Sockets are, simply put, endpoints',\n",
       " 'Many mentally ill people see their conditions deteriorate because',\n",
       " 'Email address: Leave this field']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = batch.Prompt.tolist()\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' after I got a blow dryer but I got a blow dryer and a wet towel and I',\n",
       "  ' 1 = Mem, 2 = Mem and Mem, 3 = Mem and Mem with Mem Mem and Mem',\n",
       "  ' that export to the EU, and American companies that export to the EU (currently limited to only one',\n",
       "  ' the chest and died in his arms. The shooter ran around to the back of the building and ran',\n",
       "  ' to our Terms of Service and Privacy Policy.\\n\\nEmail: First Name: Last Name: Email',\n",
       "  '. After this initial scandal, the media and members of the public began to question the reliability of the',\n",
       "  ' members of the Islamic State of Iraq and Syria (ISIS). The attack was an act of terror.\"',\n",
       "  '.\\n\\nThis is where the real magic happens.\\n\\nEvery request that makes it through the',\n",
       "  \" they don't see any alternative.\\n\\nThe world is a big place and people are going to\",\n",
       "  \" empty if you're human:\\n\\nSend\\n\\nShared folders\\n\\nThe app automatically shares\"]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuations = [batch.Continuation.tolist()]\n",
    "continuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.9185],\n",
       "        [24.8502],\n",
       "        [20.5935],\n",
       "        [10.9157],\n",
       "        [ 4.4616],\n",
       "        [14.0408],\n",
       "        [ 5.1085],\n",
       "        [ 6.1503],\n",
       "        [ 8.5458],\n",
       "        [ 7.2857]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(prompts, continuations, base_models, tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side=\"left\")\n",
    "left_tokenizer.pad_token = left_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "right_tokenizer.pad_token = right_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = left_tokenizer([\"hi\", \"hi hi hi hi\"], padding=True, return_tensors=\"pt\")\n",
    "left_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"hi\", \"hi hi hi hi\"], padding=True, return_tensors=\"pt\")\n",
    "right_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "left_input[\"input_ids\"] = left_input[\"input_ids\"].cuda()\n",
    "left_input[\"attention_mask\"] = left_input[\"attention_mask\"].cuda()\n",
    "left_loss = model(input_ids=left_input[\"input_ids\"], attention_mask=left_input[\"attention_mask\"], labels=left_input[\"input_ids\"])\n",
    "torch.exp(left_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"Thank you for coming to my party!\", \"Hello, world!\"], padding=True, return_tensors=\"pt\")\n",
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"Thank you for coming to my party!\"], padding=True, return_tensors=\"pt\")\n",
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"Hello, world!\"], padding=True, return_tensors=\"pt\")\n",
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(10.2411 + 9.4726) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
