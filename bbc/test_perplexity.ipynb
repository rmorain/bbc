{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Prefix</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Reward Type</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Continuation</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...</td>\n",
       "      <td>The DEKA prosthetic arm and Spot, the</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>latest, most powerful version of the prosthet...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>0</td>\n",
       "      <td>13.134850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...</td>\n",
       "      <td>The DEKA prosthetic arm and Spot, the</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>\"Halloween\" toy in the photo. DeKaP prostheti...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.981799</td>\n",
       "      <td>1</td>\n",
       "      <td>13.211613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...</td>\n",
       "      <td>The DEKA prosthetic arm and Spot, the</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>DEKA prosthetic arm and Spot, the DEKA prosth...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.923540</td>\n",
       "      <td>1</td>\n",
       "      <td>1.892352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...</td>\n",
       "      <td>The DEKA prosthetic arm and Spot, the</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>creator of the meme, is using the campaign as...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.739204</td>\n",
       "      <td>1</td>\n",
       "      <td>22.487940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...</td>\n",
       "      <td>The DEKA prosthetic arm and Spot, the</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>other one has a big fan club. The fans really...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0</td>\n",
       "      <td>24.868040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127995</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>negative Memes Memes Mem Mem Mem Mem Mem Mem ...</td>\n",
       "      <td>During the first half of the Eighties, huge mass</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>-murderers were allowed to roam free in the st...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.948884</td>\n",
       "      <td>1</td>\n",
       "      <td>7.587876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127996</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>negative Memes Memes Mem Mem Mem Mem Mem Mem ...</td>\n",
       "      <td>During the first half of the Eighties, huge mass</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>of meme-related websites appeared. Memes were...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.041427</td>\n",
       "      <td>0</td>\n",
       "      <td>24.156036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127997</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>negative Memes Memes Mem Mem Mem Mem Mem Mem ...</td>\n",
       "      <td>During the first half of the Eighties, huge mass</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>-produced television programmes came to define...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0</td>\n",
       "      <td>19.634359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127998</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>negative Memes Memes Mem Mem Mem Mem Mem Mem ...</td>\n",
       "      <td>During the first half of the Eighties, huge mass</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>media was in an uproar over the phenomenon of...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.945995</td>\n",
       "      <td>1</td>\n",
       "      <td>22.200739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127999</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>negative Memes Memes Mem Mem Mem Mem Mem Mem ...</td>\n",
       "      <td>During the first half of the Eighties, huge mass</td>\n",
       "      <td>SentimentRewardModel</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>-circulation magazines and newspapers such as ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.039483</td>\n",
       "      <td>0</td>\n",
       "      <td>6.984228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Epoch  Batch                                             Prefix  \\\n",
       "0           0      0   Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...   \n",
       "1           0      0   Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...   \n",
       "2           0      0   Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...   \n",
       "3           0      0   Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...   \n",
       "4           0      0   Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...   \n",
       "...       ...    ...                                                ...   \n",
       "127995      0     39   negative Memes Memes Mem Mem Mem Mem Mem Mem ...   \n",
       "127996      0     39   negative Memes Memes Mem Mem Mem Mem Mem Mem ...   \n",
       "127997      0     39   negative Memes Memes Mem Mem Mem Mem Mem Mem ...   \n",
       "127998      0     39   negative Memes Memes Mem Mem Mem Mem Mem Mem ...   \n",
       "127999      0     39   negative Memes Memes Mem Mem Mem Mem Mem Mem ...   \n",
       "\n",
       "                                                  Prompt  \\\n",
       "0                  The DEKA prosthetic arm and Spot, the   \n",
       "1                  The DEKA prosthetic arm and Spot, the   \n",
       "2                  The DEKA prosthetic arm and Spot, the   \n",
       "3                  The DEKA prosthetic arm and Spot, the   \n",
       "4                  The DEKA prosthetic arm and Spot, the   \n",
       "...                                                  ...   \n",
       "127995  During the first half of the Eighties, huge mass   \n",
       "127996  During the first half of the Eighties, huge mass   \n",
       "127997  During the first half of the Eighties, huge mass   \n",
       "127998  During the first half of the Eighties, huge mass   \n",
       "127999  During the first half of the Eighties, huge mass   \n",
       "\n",
       "                 Reward Type  Model Type  \\\n",
       "0       SentimentRewardModel  gpt2-large   \n",
       "1       SentimentRewardModel  gpt2-large   \n",
       "2       SentimentRewardModel  gpt2-large   \n",
       "3       SentimentRewardModel  gpt2-large   \n",
       "4       SentimentRewardModel  gpt2-large   \n",
       "...                      ...         ...   \n",
       "127995  SentimentRewardModel  gpt2-large   \n",
       "127996  SentimentRewardModel  gpt2-large   \n",
       "127997  SentimentRewardModel  gpt2-large   \n",
       "127998  SentimentRewardModel  gpt2-large   \n",
       "127999  SentimentRewardModel  gpt2-large   \n",
       "\n",
       "                                             Continuation Target Label  \\\n",
       "0        latest, most powerful version of the prosthet...     negative   \n",
       "1        \"Halloween\" toy in the photo. DeKaP prostheti...     negative   \n",
       "2        DEKA prosthetic arm and Spot, the DEKA prosth...     negative   \n",
       "3        creator of the meme, is using the campaign as...     negative   \n",
       "4        other one has a big fan club. The fans really...     negative   \n",
       "...                                                   ...          ...   \n",
       "127995  -murderers were allowed to roam free in the st...     negative   \n",
       "127996   of meme-related websites appeared. Memes were...     negative   \n",
       "127997  -produced television programmes came to define...     negative   \n",
       "127998   media was in an uproar over the phenomenon of...     negative   \n",
       "127999  -circulation magazines and newspapers such as ...     negative   \n",
       "\n",
       "          Reward  Correct  Perplexity  \n",
       "0       0.105900        0   13.134850  \n",
       "1       0.981799        1   13.211613  \n",
       "2       0.923540        1    1.892352  \n",
       "3       0.739204        1   22.487940  \n",
       "4       0.000197        0   24.868040  \n",
       "...          ...      ...         ...  \n",
       "127995  0.948884        1    7.587876  \n",
       "127996  0.041427        0   24.156036  \n",
       "127997  0.002879        0   19.634359  \n",
       "127998  0.945995        1   22.200739  \n",
       "127999  0.039483        0    6.984228  \n",
       "\n",
       "[128000 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../local_logs/s7qhpmoq/neutral_prompts_neg_log_s7qhpmoq.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  30.21032974391151\n",
      "median:  14.119110584259033\n",
      "mode: 0    10.208189\n",
      "Name: Perplexity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"mean: \", p.mean())\n",
    "print(\"median: \", p.median())\n",
    "print(\"mode:\", p.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926462.6875\n",
      "79145\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "print(df.Perplexity.max())\n",
    "print(df.Perplexity.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# # import numpy as np\n",
    "# # import pandas as pd\n",
    "\n",
    "# # Initialize a wandb run\n",
    "# wandb.init(project=\"histogram-example\")\n",
    "\n",
    "# # Generate some sample data\n",
    "# # data = np.random.normal(0, 1, 1000)\n",
    "# # df = pd.read_csv(\"../local_logs/4z4wflco/negative_prompts_pos_log_4z4wflco.csv\")\n",
    "# # df[stats.zscore(df.Perplexity) < 3].all(axis=1)\n",
    "# data = df.Perplexity\n",
    "\n",
    "# # Create a wandb Table with the data\n",
    "# table = wandb.Table(data=[[x] for x in data], columns=[\"values\"])\n",
    "\n",
    "# # Log the histogram\n",
    "# wandb.log({\"my_histogram\": wandb.plot.histogram(table, \"values\", title=\"Distribution of Values\")})\n",
    "\n",
    "# # Finish the run\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926462.6875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../local_logs/s7qhpmoq/neutral_prompts_neg_log_s7qhpmoq.csv\")\n",
    "\n",
    "x = df.iloc[df.Perplexity.argmax()]\n",
    "\n",
    "p = x.Perplexity\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch                                                           0\n",
       "Batch                                                          37\n",
       "Prefix           Memes Memes Memes Mem Mem Mem Mem Mem Mem Mem...\n",
       "Prompt                     News that he understands his character\n",
       "Reward Type                                  SentimentRewardModel\n",
       "Model Type                                             gpt2-large\n",
       "Continuation     MemNews<|endoftext|><|endoftext|><|endoftext|...\n",
       "Target Label                                             negative\n",
       "Reward                                                   0.993934\n",
       "Correct                                                         1\n",
       "Perplexity                                            926462.6875\n",
       "Name: 79145, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import perplexity\n",
    "\n",
    "# base_models = [AutoModelForCausalLM.from_pretrained(\"gpt2-large\").cuda()]\n",
    "base_models = [AutoModelForCausalLM.from_pretrained(\"gpt2-large\").cpu()]\n",
    "tokenizers = [AutoTokenizer.from_pretrained(\"gpt2\")]\n",
    "tokenizers[0].pad_token = tokenizers[0].eos_token\n",
    "prompts = [x.Prompt]\n",
    "# continuations = [[tokenizers[0](x.Continuation, return_tensors=\"pt\").input_ids.squeeze()]]\n",
    "continuations = [[x.Continuation]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['News that he understands his character']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' MemNews<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[926461.8125]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(prompts, continuations, base_models, tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It made my hair feel flat and uncooperative',\n",
       " 'getCashBalance ( ) ;',\n",
       " 'U.S. sanctions already prohibited American companies',\n",
       " 'The attacker was shot in',\n",
       " 'Email Sign Up By signing up you agree',\n",
       " 'Green MEPs described the newly minted test procedure as scandalous',\n",
       " '\"It appears the suspects were mainly',\n",
       " 'Sockets are, simply put, endpoints',\n",
       " 'Many mentally ill people see their conditions deteriorate because',\n",
       " 'Email address: Leave this field']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = batch.Prompt.tolist()\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' after I got a blow dryer but I got a blow dryer and a wet towel and I',\n",
       "  ' 1 = Mem, 2 = Mem and Mem, 3 = Mem and Mem with Mem Mem and Mem',\n",
       "  ' that export to the EU, and American companies that export to the EU (currently limited to only one',\n",
       "  ' the chest and died in his arms. The shooter ran around to the back of the building and ran',\n",
       "  ' to our Terms of Service and Privacy Policy.\\n\\nEmail: First Name: Last Name: Email',\n",
       "  '. After this initial scandal, the media and members of the public began to question the reliability of the',\n",
       "  ' members of the Islamic State of Iraq and Syria (ISIS). The attack was an act of terror.\"',\n",
       "  '.\\n\\nThis is where the real magic happens.\\n\\nEvery request that makes it through the',\n",
       "  \" they don't see any alternative.\\n\\nThe world is a big place and people are going to\",\n",
       "  \" empty if you're human:\\n\\nSend\\n\\nShared folders\\n\\nThe app automatically shares\"]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuations = [batch.Continuation.tolist()]\n",
    "continuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.9185],\n",
       "        [24.8502],\n",
       "        [20.5935],\n",
       "        [10.9157],\n",
       "        [ 4.4616],\n",
       "        [14.0408],\n",
       "        [ 5.1085],\n",
       "        [ 6.1503],\n",
       "        [ 8.5458],\n",
       "        [ 7.2857]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(prompts, continuations, base_models, tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side=\"left\")\n",
    "left_tokenizer.pad_token = left_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "right_tokenizer.pad_token = right_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = left_tokenizer([\"hi\", \"hi hi hi hi\"], padding=True, return_tensors=\"pt\")\n",
    "left_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"hi\", \"hi hi hi hi\"], padding=True, return_tensors=\"pt\")\n",
    "right_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "left_input[\"input_ids\"] = left_input[\"input_ids\"].cuda()\n",
    "left_input[\"attention_mask\"] = left_input[\"attention_mask\"].cuda()\n",
    "left_loss = model(input_ids=left_input[\"input_ids\"], attention_mask=left_input[\"attention_mask\"], labels=left_input[\"input_ids\"])\n",
    "torch.exp(left_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"Thank you for coming to my party!\", \"Hello, world!\"], padding=True, return_tensors=\"pt\")\n",
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"Thank you for coming to my party!\"], padding=True, return_tensors=\"pt\")\n",
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_input = right_tokenizer([\"Hello, world!\"], padding=True, return_tensors=\"pt\")\n",
    "right_input[\"input_ids\"] = right_input[\"input_ids\"].cuda()\n",
    "right_input[\"attention_mask\"] = right_input[\"attention_mask\"].cuda()\n",
    "right_loss = model(input_ids=right_input[\"input_ids\"], attention_mask=right_input[\"attention_mask\"], labels=right_input[\"input_ids\"])\n",
    "torch.exp(right_loss.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(10.2411 + 9.4726) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
